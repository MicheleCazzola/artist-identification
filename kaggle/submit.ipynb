{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":85769,"databundleVersionId":9709110,"sourceType":"competition"},{"sourceId":217400,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":185379,"modelId":207517},{"sourceId":225459,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":192309,"modelId":214248},{"sourceId":225473,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":192320,"modelId":214262},{"sourceId":226624,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":193273,"modelId":215212},{"sourceId":226726,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":193349,"modelId":215281},{"sourceId":226903,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":193488,"modelId":215418},{"sourceId":226912,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":193497,"modelId":215425}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://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@github.com/MicheleCazzola/mvlm-project.git mlvm-project\n\n!cd mlvm-project; git status","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T01:18:42.049688Z","iopub.execute_input":"2025-01-12T01:18:42.050181Z","iopub.status.idle":"2025-01-12T01:18:42.327619Z","shell.execute_reply.started":"2025-01-12T01:18:42.050152Z","shell.execute_reply":"2025-01-12T01:18:42.326778Z"}},"outputs":[{"name":"stdout","text":"fatal: destination path 'mlvm-project' already exists and is not an empty directory.\nOn branch main\nYour branch is up to date with 'origin/main'.\n\nnothing to commit, working tree clean\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"!cp -r mlvm-project/src .","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T01:18:42.328826Z","iopub.execute_input":"2025-01-12T01:18:42.329140Z","iopub.status.idle":"2025-01-12T01:18:42.468259Z","shell.execute_reply.started":"2025-01-12T01:18:42.329106Z","shell.execute_reply":"2025-01-12T01:18:42.467229Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"import os\nimport torch\nimport csv\nfrom src.model.network import MultiBranchArtistNetwork\nfrom torchvision import transforms\nfrom PIL import Image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T01:18:42.470386Z","iopub.execute_input":"2025-01-12T01:18:42.470616Z","iopub.status.idle":"2025-01-12T01:18:42.474683Z","shell.execute_reply.started":"2025-01-12T01:18:42.470594Z","shell.execute_reply":"2025-01-12T01:18:42.473927Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def preprocess_image(image_path, size, stats):\n    #imagenet = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n    transform = transforms.Compose([\n        transforms.Resize((size, size)),\n        transforms.CenterCrop((size, size)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=stats[\"mean\"], std=stats[\"std\"]),\n    ])\n    image = Image.open(image_path).convert('RGB')\n    return transform(image).unsqueeze(0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T01:18:42.475802Z","iopub.execute_input":"2025-01-12T01:18:42.476054Z","iopub.status.idle":"2025-01-12T01:18:42.489311Z","shell.execute_reply.started":"2025-01-12T01:18:42.476034Z","shell.execute_reply":"2025-01-12T01:18:42.488602Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def predict_image(model, image_tensor, class_names):\n    with torch.no_grad():\n        outputs = model(image_tensor)\n        probabilities = torch.nn.functional.softmax(outputs[0], dim=0)\n        top5_prob, top5_catid = torch.topk(probabilities, 5)\n        return [(class_names[idx], prob.item()) for idx, prob in zip(top5_catid, top5_prob)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T01:18:42.490007Z","iopub.execute_input":"2025-01-12T01:18:42.490243Z","iopub.status.idle":"2025-01-12T01:18:42.509406Z","shell.execute_reply.started":"2025-01-12T01:18:42.490224Z","shell.execute_reply":"2025-01-12T01:18:42.508681Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def evaluate_model(model, test_dir, class_names, input_size, norm_stats, device):\n    model.eval()\n    image_files = [f for f in os.listdir(test_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n\n    csv_path = '/kaggle/working/predictions.csv'\n    with open(csv_path, 'w', newline='') as csvfile:\n        writer = csv.writer(csvfile)\n        writer.writerow(['Image Name', 'Class1', 'Class2', 'Class3', 'Class4', 'Class5'])\n\n        total = len(image_files)\n        for (step, image_file) in enumerate(image_files):\n            image_path = os.path.join(test_dir, image_file)\n            image_tensor = preprocess_image(image_path, input_size, norm_stats).to(device)\n            predictions = predict_image(model, image_tensor, class_names)\n            \n            writer.writerow([image_file] + [class_name for class_name, _ in predictions])\n\n            if (step + 1) % 100 == 0:\n                print(f\"Done step {step+1}/{total}\")\n\n    print(f\"Predictions saved to {csv_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T01:18:42.510272Z","iopub.execute_input":"2025-01-12T01:18:42.510557Z","iopub.status.idle":"2025-01-12T01:18:42.522544Z","shell.execute_reply.started":"2025-01-12T01:18:42.510528Z","shell.execute_reply":"2025-01-12T01:18:42.521916Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"train_dir = \"/kaggle/input/artist-identification/artist_dataset/train\"\ntest_dir = \"/kaggle/input/artist-identification/artist_dataset/test\"\n\nNUM_CLASSES = 161\nINPUT_SIZE = 512\nNORM_STATS = {\n    \"mean\": [\n        0.47527796030044556,\n        0.42012834548950195,\n        0.3588443994522095\n    ],\n    \"std\": [\n        0.2794029116630554,\n        0.27445685863494873,\n        0.264132022857666\n    ]\n}\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-12T01:18:42.523213Z","iopub.execute_input":"2025-01-12T01:18:42.523482Z","iopub.status.idle":"2025-01-12T01:18:42.535539Z","shell.execute_reply.started":"2025-01-12T01:18:42.523457Z","shell.execute_reply":"2025-01-12T01:18:42.534721Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"MODEL_PATH = \"/kaggle/input/rnd_crop_19_bs16_aug/pytorch/default/1/best_model_19.pth.tar\"\nmodel = MultiBranchArtistNetwork(num_classes=NUM_CLASSES, use_handcrafted=False).to(DEVICE)\nif MODEL_PATH.endswith(\".pth\"):\n    model.load_state_dict(torch.load(MODEL_PATH, weights_only=True))\nelif MODEL_PATH.endswith(\".pth.tar\"):\n    model.load_state_dict(torch.load(MODEL_PATH, weights_only=False).get(\"model_state_dict\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T01:18:42.537571Z","iopub.execute_input":"2025-01-12T01:18:42.537850Z","iopub.status.idle":"2025-01-12T01:18:46.000621Z","shell.execute_reply.started":"2025-01-12T01:18:42.537818Z","shell.execute_reply":"2025-01-12T01:18:45.999840Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"class_names = sorted(os.listdir(train_dir))\n#class_names = ['dante-gabriel-rossetti', 'jan-van-eyck', 'francisco-de-zurbaran', 'william-shayer', 'martiros-saryan', 'fyodor-vasilyev', 'edwin-henry-landseer', 'giovanni-boldini', 'frans-hals', 'caspar-david-friedrich', 'thomas-cole', 'nikolay-bogdanov-belsky', 'lorenzo-lotto', 'benozzo-gozzoli', 'peter-paul-rubens', 'maurice-quentin-de-la-tour', 'hans-holbein-the-younger', 'theodore-gericault', 'maerten-van-heemskerck', 'ivan-shishkin', 'henri-fantin-latour', 'james-mcneill-whistler', 'anders-zorn', 'eugene-delacroix', 'julius-leblanc-stewart', 'giorgio-vasari', 'thomas-eakins', 'john-crome', 'albrecht-durer', 'bartolome-esteban-murillo', 'thomas-gainsborough', 'paolo-veronese', 'pieter-de-hooch', 'rembrandt', 'george-morland', 'albrecht-altdorfer', 'pieter-bruegel-the-elder', 'winslow-homer', 'viktor-vasnetsov', 'john-french-sloan', 'jan-steen', 'andrei-ryabushkin', 'n.c.-wyeth', 'giovanni-battista-tiepolo', 'jacob-jordaens', 'boris-kustodiev', 'salvador-dali', 'antoine-watteau', 'anthony-van-dyck', 'william-adolphe-bouguereau', 'mabuse', 'hans-memling', 'el-greco', 'andrea-del-sarto', 'jean-honore-fragonard', 'ivan-kramskoy', 'titian', 'charles-francois-daubigny', 'lev-lagorio', 'pietro-longhi', 'vasily-polenov', 'gustave-dore', 'orest-kiprensky', 'karl-bodmer', 'agnolo-bronzino', 'bernardo-bellotto', 'george-stubbs', 'correggio', 'john-singer-sargent', 'jacopo-pontormo', 'benjamin-west', 'camille-pissarro', 'volodymyr-orlovsky', 'pavel-svinyin', 'valentin-serov', 'esaias-van-de-velde', 'ivan-vladimirov', 'jan-matejko', 'tintoretto', 'alexey-venetsianov', 'paul-cezanne', 'cornelis-springer', 'pyotr-konchalovsky', 'sir-lawrence-alma-tadema', 'john-hoppner', 'vincent-van-gogh', 'jean-baptiste-simeon-chardin', 'francesco-guardi', 'paolo-uccello', 'rogier-van-der-weyden', 'diego-velazquez', 'francisco-goya', 'piero-della-francesca', 'vladimir-makovsky', 'rudolf-von-alt', 'giovanni-bellini', 'louise-elisabeth-vigee-le-brun', 'raphael', 'john-constable', 'edouard-manet', 'karl-bryullov', 'david-teniers-the-younger', 'domenico-ghirlandaio', 'vasily-surikov', 'guido-reni', 'gerard-david', 'alfred-stevens', 'antoine-pesne', 'john-atkinson-grimshaw', 'filippo-lippi', 'canaletto', 'vittore-carpaccio', 'pietro-perugino', 'carlo-crivelli', 'frans-snyders', 'gerrit-dou', 'william-hogarth', 'giovanni-domenico-tiepolo', 'john-william-waterhouse', 'gian-lorenzo-bernini', 'dmitry-levitzky', 'konstantin-makovsky', 'camille-corot', 'joseph-wright', 'joshua-reynolds', 'luca-signorelli', 'edward-burne-jones', 'gustave-courbet', 'vasily-perov', 'ilya-repin', 'nicholas-roerich', 'eugene-boudin', 'james-tissot', 'nikolai-ge', 'vladimir-borovikovsky', 'odilon-redon', 'johan-hendrik-weissenbruch', 'taras-shevchenko', 'leonardo-da-vinci', 'isaac-levitan', 'william-turner', 'adriaen-van-ostade', 'jean-francois-millet', 'jean-fouquet', 'vasily-vereshchagin', 'aleksey-savrasov', 'sandro-botticelli', 'fyodor-bronnikov', 'henry-raeburn', 'hieronymus-bosch', 'edward-hopper', 'vasily-tropinin', 'john-everett-millais', 'arkhip-kuindzhi', 'theodore-rousseau', 'andrea-mantegna', 'caravaggio', 'martin-schongauer', 'michelangelo', 'fra-angelico', 'ivan-aivazovsky']\nassert len(class_names) == NUM_CLASSES","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T01:18:46.001772Z","iopub.execute_input":"2025-01-12T01:18:46.001987Z","iopub.status.idle":"2025-01-12T01:18:46.006414Z","shell.execute_reply.started":"2025-01-12T01:18:46.001969Z","shell.execute_reply":"2025-01-12T01:18:46.005614Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"evaluate_model(model, test_dir, class_names, INPUT_SIZE, NORM_STATS, DEVICE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T01:18:46.007351Z","iopub.execute_input":"2025-01-12T01:18:46.007610Z","iopub.status.idle":"2025-01-12T01:20:56.535060Z","shell.execute_reply.started":"2025-01-12T01:18:46.007585Z","shell.execute_reply":"2025-01-12T01:20:56.534143Z"}},"outputs":[{"name":"stdout","text":"Done step 100/3960\nDone step 200/3960\nDone step 300/3960\nDone step 400/3960\nDone step 500/3960\nDone step 600/3960\nDone step 700/3960\nDone step 800/3960\nDone step 900/3960\nDone step 1000/3960\nDone step 1100/3960\nDone step 1200/3960\nDone step 1300/3960\nDone step 1400/3960\nDone step 1500/3960\nDone step 1600/3960\nDone step 1700/3960\nDone step 1800/3960\nDone step 1900/3960\nDone step 2000/3960\nDone step 2100/3960\nDone step 2200/3960\nDone step 2300/3960\nDone step 2400/3960\nDone step 2500/3960\nDone step 2600/3960\nDone step 2700/3960\nDone step 2800/3960\nDone step 2900/3960\nDone step 3000/3960\nDone step 3100/3960\nDone step 3200/3960\nDone step 3300/3960\nDone step 3400/3960\nDone step 3500/3960\nDone step 3600/3960\nDone step 3700/3960\nDone step 3800/3960\nDone step 3900/3960\nPredictions saved to /kaggle/working/predictions.csv\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"!ls -la /kaggle/working","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T01:21:12.383615Z","iopub.execute_input":"2025-01-12T01:21:12.383975Z","iopub.status.idle":"2025-01-12T01:21:12.524615Z","shell.execute_reply.started":"2025-01-12T01:21:12.383946Z","shell.execute_reply":"2025-01-12T01:21:12.523601Z"}},"outputs":[{"name":"stdout","text":"total 388\ndrwxr-xr-x  5 root root   4096 Jan 12 01:03 .\ndrwxr-xr-x  5 root root   4096 Jan 12 00:59 ..\ndrwxr-xr-x 10 root root   4096 Jan 12 01:03 mlvm-project\n-rw-r--r--  1 root root 374166 Jan 12 01:20 predictions.csv\ndrwxr-xr-x  9 root root   4096 Jan 12 01:03 src\ndrwxr-xr-x  2 root root   4096 Jan 12 01:00 .virtual_documents\n","output_type":"stream"}],"execution_count":27}]}