{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "from src.trainer.metrics import Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6667)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = tensor([2, 2, 1, 0, 0])\n",
    "preds = tensor([2, 1, 1, 0, 1])\n",
    "metric = Metrics(3, 1).mca\n",
    "metric.update(preds, target)\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 0, 0]), tensor([1, 1, 1]), tensor([0, 1, 0]), tensor([2, 2, 3]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.fn, metric.tp, metric.fp, metric.tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7500)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(metric.tp.sum()) / (metric.tp.sum() + metric.fn.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from topk.svm import SmoothTopkSVM\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(torch.nn.Module):\n",
    "    def __init__(self, in_features: int, out_classes: int):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.linear = torch.nn.Linear(in_features, out_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 64\n",
    "C = 10\n",
    "K = 3\n",
    "EPOCHS = 3\n",
    "alpha = 0.7\n",
    "tau = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = CIFAR10(root='./data', train=True, download=True, transform=transformations)\n",
    "testset = CIFAR10(root='./data', train=False, download=True, transform=transformations)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=B, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=B, shuffle=False)\n",
    "\n",
    "m1 = MulticlassAccuracy(num_classes=C, average=\"micro\", top_k=1)\n",
    "m3 = MulticlassAccuracy(num_classes=C, average=\"micro\", top_k=K)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(782, 157)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainloader), len(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, trainloader, criterion, optimizer, metrics):\n",
    "    m1, m3 = metrics\n",
    "    m1.reset()\n",
    "    m3.reset()\n",
    "    step = 0\n",
    "    for i in range(EPOCHS):\n",
    "        model.train()\n",
    "        for inputs, labels in trainloader:\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (step + 1) % 50 == 0:\n",
    "                print(f\"Step {step + 1}, loss: {loss.item()}\")\n",
    "            \n",
    "            m1.update(outputs, labels)\n",
    "            m3.update(outputs, labels)\n",
    "            \n",
    "            step += 1\n",
    "            \n",
    "        print(f\"End of epoch {i+1}/{EPOCHS}, accuracies: {m1.compute().item() * 100:.2f}, {m3.compute().item() * 100:.2f}\")\n",
    "        \n",
    "    print(f\"Top-1 accuracy: {m1.compute().item() * 100:.2f}\")\n",
    "    print(f\"Top-3 accuracy: {m3.compute().item() * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def test(model, testloader, criterion, metrics: tuple[MulticlassAccuracy, MulticlassAccuracy]):\n",
    "    m1, m3 = metrics\n",
    "    m1.reset()\n",
    "    m3.reset()\n",
    "    \n",
    "    model.eval()\n",
    "    loss_tot = 0\n",
    "    step = 0\n",
    "    for inputs, labels in testloader:\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        m1.update(outputs, labels)\n",
    "        m3.update(outputs, labels)\n",
    "        \n",
    "        if (step + 1) % 50 == 0:\n",
    "            print(f\"Step {step + 1}, loss: {loss.item()}\")\n",
    "            \n",
    "        loss_tot += loss.item()\n",
    "        step += 1\n",
    "        \n",
    "    print(f\"Top-1 accuracy: {m1.compute().item() * 100:.2f}\")\n",
    "    print(f\"Top-3 accuracy: {m3.compute().item() * 100:.2f}\")\n",
    "    print(f\"Loss: {loss_tot / len(testloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.mobilenet_v2(weights=\"DEFAULT\")\n",
    "model.classifier[-1] = torch.nn.Linear(model.classifier[-1].in_features, C)\n",
    "for param in model.features[:15].parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "hard_criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 50, loss: 1.6758540868759155\n",
      "Step 100, loss: 1.5768574476242065\n",
      "Step 150, loss: 1.6489557027816772\n",
      "Step 200, loss: 1.6039656400680542\n",
      "Step 250, loss: 1.3739254474639893\n",
      "Step 300, loss: 1.4427231550216675\n",
      "Step 350, loss: 1.4571537971496582\n",
      "Step 400, loss: 1.4831770658493042\n",
      "Step 450, loss: 1.4126404523849487\n",
      "Step 500, loss: 1.3841454982757568\n",
      "Step 550, loss: 1.558480978012085\n",
      "Step 600, loss: 1.289584994316101\n",
      "Step 650, loss: 1.2016512155532837\n",
      "Step 700, loss: 1.3622970581054688\n",
      "Step 750, loss: 1.5817837715148926\n",
      "End of epoch 1/3, accuracies: 48.63, 80.10\n",
      "Step 800, loss: 1.3741772174835205\n",
      "Step 850, loss: 1.688345193862915\n",
      "Step 900, loss: 1.4620552062988281\n",
      "Step 950, loss: 1.1700478792190552\n",
      "Step 1000, loss: 1.2572259902954102\n",
      "Step 1050, loss: 1.2648059129714966\n",
      "Step 1100, loss: 1.0765782594680786\n",
      "Step 1150, loss: 1.2494066953659058\n",
      "Step 1200, loss: 1.087184190750122\n",
      "Step 1250, loss: 1.5420562028884888\n",
      "Step 1300, loss: 1.3751832246780396\n",
      "Step 1350, loss: 1.0642421245574951\n",
      "Step 1400, loss: 1.4163336753845215\n",
      "Step 1450, loss: 1.4068716764450073\n",
      "Step 1500, loss: 1.3252116441726685\n",
      "Step 1550, loss: 1.3577880859375\n",
      "End of epoch 2/3, accuracies: 52.00, 82.58\n",
      "Step 1600, loss: 1.1345038414001465\n",
      "Step 1650, loss: 1.2339823246002197\n",
      "Step 1700, loss: 1.1323548555374146\n",
      "Step 1750, loss: 0.9298533201217651\n",
      "Step 1800, loss: 1.1021430492401123\n",
      "Step 1850, loss: 1.2296820878982544\n",
      "Step 1900, loss: 1.200749397277832\n",
      "Step 1950, loss: 1.141227126121521\n",
      "Step 2000, loss: 1.1843091249465942\n",
      "Step 2050, loss: 1.1611183881759644\n",
      "Step 2100, loss: 1.079559326171875\n",
      "Step 2150, loss: 1.4271612167358398\n",
      "Step 2200, loss: 1.2766830921173096\n",
      "Step 2250, loss: 1.229943037033081\n",
      "Step 2300, loss: 1.236423134803772\n",
      "End of epoch 3/3, accuracies: 53.77, 83.95\n",
      "Top-1 accuracy: 53.77\n",
      "Top-3 accuracy: 83.95\n"
     ]
    }
   ],
   "source": [
    "train(model, trainloader, hard_criterion, optimizer, (m1, m3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 50, loss: 1.1821616888046265\n",
      "Step 100, loss: 1.1528807878494263\n",
      "Step 150, loss: 1.150281310081482\n",
      "Top-1 accuracy: 58.98\n",
      "Top-3 accuracy: 87.01\n",
      "Loss: 1.179604022366226\n"
     ]
    }
   ],
   "source": [
    "test(model, testloader, hard_criterion, (m1, m3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting tau to 0.2\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.mobilenet_v2(weights=\"DEFAULT\")\n",
    "model.classifier[-1] = torch.nn.Linear(model.classifier[-1].in_features, C)\n",
    "for param in model.features[:15].parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "smooth_criterion = SmoothTopkSVM(C, alpha, tau, K)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 50, loss: 0.47312334179878235\n",
      "Step 100, loss: 0.2778180241584778\n",
      "Step 150, loss: 0.37850090861320496\n",
      "Step 200, loss: 0.32945364713668823\n",
      "Step 250, loss: 0.33578747510910034\n",
      "Step 300, loss: 0.31762412190437317\n",
      "Step 350, loss: 0.2790426015853882\n",
      "Step 400, loss: 0.43221235275268555\n",
      "Step 450, loss: 0.33978256583213806\n",
      "Step 500, loss: 0.2622852921485901\n",
      "Step 550, loss: 0.324231892824173\n",
      "Step 600, loss: 0.42628371715545654\n",
      "Step 650, loss: 0.28953292965888977\n",
      "Step 700, loss: 0.31066590547561646\n",
      "Step 750, loss: 0.5093371868133545\n",
      "End of epoch 1/3, accuracies: 47.15, 80.02\n",
      "Step 800, loss: 0.28892990946769714\n",
      "Step 850, loss: 0.3473959267139435\n",
      "Step 900, loss: 0.3689599335193634\n",
      "Step 950, loss: 0.27272266149520874\n",
      "Step 1000, loss: 0.24775241315364838\n",
      "Step 1050, loss: 0.14146298170089722\n",
      "Step 1100, loss: 0.2529749572277069\n",
      "Step 1150, loss: 0.3322805166244507\n",
      "Step 1200, loss: 0.24014617502689362\n",
      "Step 1250, loss: 0.33436182141304016\n",
      "Step 1300, loss: 0.22790366411209106\n",
      "Step 1350, loss: 0.2586853802204132\n",
      "Step 1400, loss: 0.18130989372730255\n",
      "Step 1450, loss: 0.3831648826599121\n",
      "Step 1500, loss: 0.21253983676433563\n",
      "Step 1550, loss: 0.1857743263244629\n",
      "End of epoch 2/3, accuracies: 49.87, 82.26\n",
      "Step 1600, loss: 0.15983542799949646\n",
      "Step 1650, loss: 0.2551189661026001\n",
      "Step 1700, loss: 0.1105838268995285\n",
      "Step 1750, loss: 0.17027230560779572\n",
      "Step 1800, loss: 0.34519487619400024\n",
      "Step 1850, loss: 0.31466037034988403\n",
      "Step 1900, loss: 0.25426968932151794\n",
      "Step 1950, loss: 0.33922165632247925\n",
      "Step 2000, loss: 0.2050965428352356\n",
      "Step 2050, loss: 0.295773983001709\n",
      "Step 2100, loss: 0.25640439987182617\n",
      "Step 2150, loss: 0.22468653321266174\n",
      "Step 2200, loss: 0.24037736654281616\n",
      "Step 2250, loss: 0.28828689455986023\n",
      "Step 2300, loss: 0.22114118933677673\n",
      "End of epoch 3/3, accuracies: 51.20, 83.39\n",
      "Top-1 accuracy: 51.20\n",
      "Top-3 accuracy: 83.39\n"
     ]
    }
   ],
   "source": [
    "train(model, trainloader, smooth_criterion, optimizer, (m1, m3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 50, loss: 0.30828139185905457\n",
      "Step 100, loss: 0.1869034320116043\n",
      "Step 150, loss: 0.15774597227573395\n",
      "Top-1 accuracy: 55.56\n",
      "Top-3 accuracy: 86.16\n",
      "Loss: 0.23916984719645445\n"
     ]
    }
   ],
   "source": [
    "test(model, testloader, smooth_criterion, (m1, m3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
